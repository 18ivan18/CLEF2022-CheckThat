{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/18ivan18/CLEF2022-CheckThat/blob/main/CLEF2022Task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "k9QeYxj12Wmc"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -q\n",
        "\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizerFast # base bert\n",
        "from transformers import AutoModel, AutoTokenizer  # bertweet\n",
        "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel, RobertaTokenizerFast  # roberta\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda=torch.cuda.is_available()\n",
        "device = 'cuda' if use_cuda else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aoLPuvyLFrE2",
        "outputId": "95398956-fe5e-4b0a-b87c-5ed1c2a53aee"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-w6YixOgSRn"
      },
      "source": [
        "# [CLEF2022-CheckThat!](https://sites.google.com/view/clef2022-checkthat/home)\n",
        "## [Task 1: Identifying Relevant Claims in Tweets](https://sites.google.com/view/clef2022-checkthat/tasks/task-1-identifying-relevant-claims-in-tweets)\n",
        "\n",
        "**Subtask 1A:** Check-worthiness of tweets: Given a tweet, predict whether it is worth fact-checking. This task is defined with binary labels: Yes and No.. This is a classification task. This subtasks runs in 6 languages:\n",
        "\n",
        "- Arabic\n",
        "- Bulgarian\n",
        "- Dutch\n",
        "- English\n",
        "- Spanish\n",
        "- Turkish\n",
        "\n",
        "In this task I'll focus on English and Bulgarian only throughout all subtasks. English as the most popular language and presumably the models are best fitted for it, and Bulgarian as my native language.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSwIn6Z3ipAH"
      },
      "source": [
        "## First let's download the data and run the baseline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiTwr25XqHaE",
        "outputId": "91d8f441-cb4a-439d-e6d8-d4a2426bca7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'clef2022-checkthat-lab' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://gitlab.com/checkthat_lab/clef2022-checkthat-lab/clef2022-checkthat-lab.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "NBcKn7v3G1Fp"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "data_directory_name=\"data/\"\n",
        "# Unzip target file\n",
        "def unzip(filename):\n",
        "  with zipfile.ZipFile(filename, mode=\"r\") as archive:\n",
        "     archive.extractall(data_directory_name)\n",
        "\n",
        "def prepare_data(lang, subtask, subtask_id):\n",
        "  unzip(f'/content/clef2022-checkthat-lab/task1/data/subtasks-{lang}/test/CT22_{lang}_{subtask_id}_{subtask}_test.zip')\n",
        "  unzip(f'/content/clef2022-checkthat-lab/task1/data/subtasks-{lang}/CT22_{lang}_{subtask_id}_{subtask}.zip')\n",
        "  unzip(f'/content/clef2022-checkthat-lab/task1/data/subtasks-{lang}/test/CT22_{lang}_{subtask_id}_{subtask}_test_gold.zip')\n",
        "  \n",
        "  df_train = pd.read_csv(f'/content/data/CT22_{lang}_{subtask_id}_{subtask}_train.tsv', sep='\\t')\n",
        "  df_train = pd.DataFrame({\n",
        "        'text' : df_train['tweet_text'],\n",
        "        'label' : df_train['class_label']\n",
        "  })\n",
        "\n",
        "  df_valid = pd.read_csv(f'/content/data/CT22_{lang}_{subtask_id}_{subtask}_dev.tsv', sep='\\t')\n",
        "  df_valid = pd.DataFrame({\n",
        "      'text' : df_valid['tweet_text'],\n",
        "      'label' : df_valid['class_label']\n",
        "  })\n",
        "\n",
        "  df_test = pd.read_csv(f'/content/data/CT22_{lang}_{subtask_id}_{subtask}_test.tsv', sep='\\t')\n",
        "  return df_train, df_valid, df_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "Mwjhb0CeIA-t"
      },
      "outputs": [],
      "source": [
        "lang='english'\n",
        "subtask='checkworthy'\n",
        "subtask_id='1A'\n",
        "results_fpath=f'data/subtask{subtask_id}_{subtask}_{lang}.tsv'\n",
        "run_id='izarabadzh'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeO6ohCeIB9s",
        "outputId": "0f3c86c6-3330-41eb-c4e1-28abca5bd888"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(None, {0: 0, 1: 1})"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "df_train, df_valid, df_test = prepare_data(lang, subtask, subtask_id)\n",
        "\n",
        "def encode_labels(labels):\n",
        "  i = 0\n",
        "  labels_dict = defaultdict()\n",
        "  for label in labels.unique():\n",
        "      labels_dict[label] = i\n",
        "      i += 1\n",
        "  return labels_dict\n",
        "    \n",
        "encode_labels(df_train['label'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_dict(dict):\n",
        "  return {v: k for k, v in dict.items()}\n",
        "inverse_dict(encode_labels(df_train['label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8F1UrHzv5en",
        "outputId": "e777cfd6-f151-42f2-d2ca-6b5d2abe3cbd"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0, 1: 1}"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mslZbwUHlKE3",
        "outputId": "adbfdeb1-865b-4a85-d317-ad2139da9bf4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  India's gift of 100,000 COVID-19 vaccines arri...      0\n",
              "1  As part of the ongoing nationwide vaccination ...      0\n",
              "2  Pleased to receive 50,000 doses of Covid-19 va...      0\n",
              "3  Four former presidents have banded together fo...      0\n",
              "4  WSJ: All three of Russia's main intelligence s...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec466bf2-362d-4818-b94d-ce951fd76c56\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>India's gift of 100,000 COVID-19 vaccines arri...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>As part of the ongoing nationwide vaccination ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pleased to receive 50,000 doses of Covid-19 va...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Four former presidents have banded together fo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WSJ: All three of Russia's main intelligence s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec466bf2-362d-4818-b94d-ce951fd76c56')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec466bf2-362d-4818-b94d-ce951fd76c56 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec466bf2-362d-4818-b94d-ce951fd76c56');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "hvBqptpsiQpz",
        "outputId": "57b0a48b-6ee8-4bf0-a225-1714c2d71f97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f42a3e5d5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 158
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "df_train.groupby(['label']).size().plot.bar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aHpqAgo3T_s6",
        "outputId": "93265be7-bf0c-47c8-cc20-f92ab1874c18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  Native American communities have been hit hard...      0\n",
              "1  ALERT: CVS Pharmacy is now offering COVID-19 v...      0\n",
              "2  #COVID19 vaccines are an important tool to hel...      0\n",
              "3  Pfizer reports that IRL the vaccine is 97% eff...      0\n",
              "4  Vaccines are complex medicines. Europeans can ...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e2d1b66-0c3a-4760-acec-a6f5518d78fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Native American communities have been hit hard...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ALERT: CVS Pharmacy is now offering COVID-19 v...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#COVID19 vaccines are an important tool to hel...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pfizer reports that IRL the vaccine is 97% eff...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vaccines are complex medicines. Europeans can ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e2d1b66-0c3a-4760-acec-a6f5518d78fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e2d1b66-0c3a-4760-acec-a6f5518d78fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e2d1b66-0c3a-4760-acec-a6f5518d78fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ],
      "source": [
        "df_valid.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5i8IzVt65v9"
      },
      "source": [
        "## Baseline.\n",
        "Here we just use the script provided by the creators of CLEF.\n",
        "\n",
        "```\n",
        "#python -t /home/bjit/Nandi-AI/NLP/clef2022-checkthat-lab/task1/data/subtasks-english/CT22_english_1B_claim/CT22_english_1B_claim_train.tsv -d /home/bjit/Nandi-AI/NLP/clef2022-checkthat-lab/task1/data/subtasks-english/CT22_english_1B_claim/CT22_english_1B_claim_dev.tsv -l english -a claim\n",
        "```\n",
        "\n",
        "Majority Baseline for Subtask-checkworthy--english F1 (positive class): 0.0\n",
        "\n",
        "Random Baseline for Subtask-checkworthy--english F1 (positive class): 0.23376623376623376  \n",
        "\n",
        "Ngram Baseline for Subtask-checkworthy--english F1 (positive class): 0.34615384615384615"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train data\n",
        "df_train['label'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZOhZymTOUeM",
        "outputId": "3790d613-a249-4881-bb0b-71b7f5eb61c3"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2122,)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "\n",
        "class ModelName(Enum):\n",
        "     BERT = 'Bert'\n",
        "     BERTWEET = 'Bertweet'\n",
        "     ROBERTA = 'Roberta'\n",
        "\n",
        "class Language(Enum):\n",
        "     BULGARIAN = 'bulgarian'\n",
        "     ENGLISH = 'english'\n",
        "     SPANISH = 'spanish'\n",
        "     TURKISH = 'turkish'\n",
        "     DUTCH = 'dutch'\n",
        "     ARABIC = 'arabic'\n",
        "     \n",
        "     \n",
        "model_name: ModelName = ModelName.BERT\n",
        "language_name: Language = Language.ENGLISH"
      ],
      "metadata": {
        "id": "9ariTRz1Jdyf"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"This contains various tokenizer, uncomment and use the tokenizer as per the model requirement\"\"\"\n",
        "\n",
        "def get_tokenizer(model_name: ModelName):\n",
        "  if model_name==ModelName.BERT:\n",
        "    if language_name==Language.ENGLISH:\n",
        "      return BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "    else:\n",
        "      return BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "  if model_name==ModelName.BERTWEET:\n",
        "    return AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n",
        "  if model_name==ModelName.ROBERTA:\n",
        "    return RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
        "\n",
        "tokenizer=get_tokenizer(model_name)\n",
        "tokenizer"
      ],
      "metadata": {
        "id": "wrCajFuMyBP8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981bd444-b5f4-4f13-aa92-358cd947ec8c"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizer(name_or_path='bert-base-cased', vocab_size=28996, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "_ZoVLdMlZqC_"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        labels = encode_labels(df['label'])\n",
        "        self.labels = [labels[label] for label in df['label']]\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length=512, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['text']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "4Sfa_ONObaYv"
      },
      "outputs": [],
      "source": [
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, transformer, dropout=0.5, target=2):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.transformer = transformer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, target)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.transformer(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "wfE7iSu4b38V"
      },
      "outputs": [],
      "source": [
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "                \n",
        "                batch_loss = criterion(output, train_label.long())\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "\n",
        "                    batch_loss = criterion(output, val_label.long())\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "            \n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "                  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transformer(model_name: ModelName):\n",
        "  if model_name==ModelName.BERT:\n",
        "    if language_name==Language.ENGLISH:\n",
        "      return BertModel.from_pretrained(\"bert-base-cased\")\n",
        "    else:\n",
        "      return BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "  if model_name==ModelName.BERTWEET:\n",
        "    return AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
        "  if model_name==ModelName.ROBERTA:\n",
        "    return RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "transformer=get_transformer(model_name)"
      ],
      "metadata": {
        "id": "hNQ-ar9fL2NE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c601b3-926a-4c97-91f1-34a1b931b182"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "H_iyt63hMTPr"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1A=BertClassifier(transformer)\n",
        "print(f'The model has {count_parameters(model_1A):,} trainable parameters')\n"
      ],
      "metadata": {
        "id": "Kbhz-0OsL0uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d9cb4da-cd69-4ccb-8fcf-6093f5ac785d"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 108,311,810 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR=1e-6 \n",
        "EPOCHS=15"
      ],
      "metadata": {
        "id": "OuUW6CT5TwJJ"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model_1A.named_parameters():\n",
        "  if \"pooler\" in name or \"linear\" in name: \n",
        "    param.requires_grad = True\n",
        "  else:\n",
        "    param.requires_grad = False\n",
        "  print(name, param.shape, param.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model_1A):,} trainable parameters')"
      ],
      "metadata": {
        "id": "AcOiT4WmMYYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bfcf0eb-7ad3-426f-ca30-663e49017b2b"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformer.embeddings.word_embeddings.weight torch.Size([28996, 768]) False\n",
            "transformer.embeddings.position_embeddings.weight torch.Size([512, 768]) False\n",
            "transformer.embeddings.token_type_embeddings.weight torch.Size([2, 768]) False\n",
            "transformer.embeddings.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.embeddings.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.0.attention.self.query.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.0.attention.self.query.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.0.attention.self.key.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.0.attention.self.key.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.0.attention.self.value.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.0.attention.self.value.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.0.attention.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "transformer.encoder.layer.0.intermediate.dense.bias torch.Size([3072]) False\n",
            "transformer.encoder.layer.0.output.dense.weight torch.Size([768, 3072]) False\n",
            "transformer.encoder.layer.0.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.0.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.0.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.1.attention.self.query.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.1.attention.self.query.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.1.attention.self.key.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.1.attention.self.key.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.1.attention.self.value.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.1.attention.self.value.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.1.attention.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "transformer.encoder.layer.1.intermediate.dense.bias torch.Size([3072]) False\n",
            "transformer.encoder.layer.1.output.dense.weight torch.Size([768, 3072]) False\n",
            "transformer.encoder.layer.1.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.1.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.1.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.2.attention.self.query.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.2.attention.self.query.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.2.attention.self.key.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.2.attention.self.key.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.2.attention.self.value.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.2.attention.self.value.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.2.attention.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "transformer.encoder.layer.2.intermediate.dense.bias torch.Size([3072]) False\n",
            "transformer.encoder.layer.2.output.dense.weight torch.Size([768, 3072]) False\n",
            "transformer.encoder.layer.2.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.2.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.2.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.3.attention.self.query.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.3.attention.self.query.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.3.attention.self.key.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.3.attention.self.key.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.3.attention.self.value.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.3.attention.self.value.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.3.attention.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "transformer.encoder.layer.3.intermediate.dense.bias torch.Size([3072]) False\n",
            "transformer.encoder.layer.3.output.dense.weight torch.Size([768, 3072]) False\n",
            "transformer.encoder.layer.3.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.3.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.3.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.4.attention.self.query.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.4.attention.self.query.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.4.attention.self.key.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.4.attention.self.key.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.4.attention.self.value.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.4.attention.self.value.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.4.attention.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "transformer.encoder.layer.4.intermediate.dense.bias torch.Size([3072]) False\n",
            "transformer.encoder.layer.4.output.dense.weight torch.Size([768, 3072]) False\n",
            "transformer.encoder.layer.4.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.4.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.4.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.5.attention.self.query.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.5.attention.self.query.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.5.attention.self.key.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.5.attention.self.key.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.5.attention.self.value.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.5.attention.self.value.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.5.attention.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "transformer.encoder.layer.5.intermediate.dense.bias torch.Size([3072]) False\n",
            "transformer.encoder.layer.5.output.dense.weight torch.Size([768, 3072]) False\n",
            "transformer.encoder.layer.5.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.5.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.5.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.6.attention.self.query.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.6.attention.self.query.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.6.attention.self.key.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.6.attention.self.key.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.6.attention.self.value.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.6.attention.self.value.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.6.attention.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "transformer.encoder.layer.6.intermediate.dense.bias torch.Size([3072]) False\n",
            "transformer.encoder.layer.6.output.dense.weight torch.Size([768, 3072]) False\n",
            "transformer.encoder.layer.6.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.6.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.6.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.7.attention.self.query.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.7.attention.self.query.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.7.attention.self.key.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.7.attention.self.key.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.7.attention.self.value.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.7.attention.self.value.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.7.attention.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "transformer.encoder.layer.7.intermediate.dense.bias torch.Size([3072]) False\n",
            "transformer.encoder.layer.7.output.dense.weight torch.Size([768, 3072]) False\n",
            "transformer.encoder.layer.7.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.7.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.7.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.8.attention.self.query.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.8.attention.self.query.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.8.attention.self.key.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.8.attention.self.key.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.8.attention.self.value.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.8.attention.self.value.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.8.attention.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "transformer.encoder.layer.8.intermediate.dense.bias torch.Size([3072]) False\n",
            "transformer.encoder.layer.8.output.dense.weight torch.Size([768, 3072]) False\n",
            "transformer.encoder.layer.8.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.8.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.8.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.9.attention.self.query.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.9.attention.self.query.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.9.attention.self.key.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.9.attention.self.key.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.9.attention.self.value.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.9.attention.self.value.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.9.attention.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "transformer.encoder.layer.9.intermediate.dense.bias torch.Size([3072]) False\n",
            "transformer.encoder.layer.9.output.dense.weight torch.Size([768, 3072]) False\n",
            "transformer.encoder.layer.9.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.9.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.9.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.10.attention.self.query.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.10.attention.self.query.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.10.attention.self.key.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.10.attention.self.key.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.10.attention.self.value.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.10.attention.self.value.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.10.attention.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "transformer.encoder.layer.10.intermediate.dense.bias torch.Size([3072]) False\n",
            "transformer.encoder.layer.10.output.dense.weight torch.Size([768, 3072]) False\n",
            "transformer.encoder.layer.10.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.10.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.10.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.11.attention.self.query.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.11.attention.self.query.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.11.attention.self.key.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.11.attention.self.key.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.11.attention.self.value.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.11.attention.self.value.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768]) False\n",
            "transformer.encoder.layer.11.attention.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768]) False\n",
            "transformer.encoder.layer.11.intermediate.dense.bias torch.Size([3072]) False\n",
            "transformer.encoder.layer.11.output.dense.weight torch.Size([768, 3072]) False\n",
            "transformer.encoder.layer.11.output.dense.bias torch.Size([768]) False\n",
            "transformer.encoder.layer.11.output.LayerNorm.weight torch.Size([768]) False\n",
            "transformer.encoder.layer.11.output.LayerNorm.bias torch.Size([768]) False\n",
            "transformer.pooler.dense.weight torch.Size([768, 768]) True\n",
            "transformer.pooler.dense.bias torch.Size([768]) True\n",
            "linear.weight torch.Size([2, 768]) True\n",
            "linear.bias torch.Size([2]) True\n",
            "The model has 592,130 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "Yh2AEtQ02S40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c29897b-3563-4536-aece-6bd8b3125003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1061/1061 [01:13<00:00, 14.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.288 | Train Accuracy:  0.766 | Val Loss:  0.276 | Val Accuracy:  0.769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1061/1061 [01:13<00:00, 14.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.268 | Train Accuracy:  0.786 | Val Loss:  0.282 | Val Accuracy:  0.769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1061/1061 [01:14<00:00, 14.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.268 | Train Accuracy:  0.790 | Val Loss:  0.268 | Val Accuracy:  0.774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1061/1061 [01:15<00:00, 14.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  0.259 | Train Accuracy:  0.788 | Val Loss:  0.273 | Val Accuracy:  0.774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1061/1061 [01:15<00:00, 14.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  0.262 | Train Accuracy:  0.788 | Val Loss:  0.271 | Val Accuracy:  0.774\n"
          ]
        }
      ],
      "source": [
        "# train(model_1A, df_train, df_valid, LR, EPOCHS)\n",
        "\n",
        "# torch.save(model_1A.state_dict(), f\"model_{lang}_{subtask}_{subtask_id}_{EPOCHS}_epochs.bin\")\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "RuCDcJO6pZJQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1ea1a4a8-ca50-47dc-ec49-da498ed0e932"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      topic             tweet_id  \\\n",
              "0  COVID-19  1425267281202909184   \n",
              "1  COVID-19  1387113304959504384   \n",
              "2  COVID-19  1379498353294069760   \n",
              "3  COVID-19  1369843850223759362   \n",
              "4  COVID-19  1352425395375759363   \n",
              "\n",
              "                                           tweet_url  \\\n",
              "0  http://twitter.com/user/status/142526728120290...   \n",
              "1  http://twitter.com/user/status/138711330495950...   \n",
              "2  http://twitter.com/user/status/137949835329406...   \n",
              "3  http://twitter.com/user/status/136984385022375...   \n",
              "4  http://twitter.com/user/status/135242539537575...   \n",
              "\n",
              "                                          tweet_text  \n",
              "0  i was a vaccine checker tonight at my venue an...  \n",
              "1  I asked the nurse giving my vaccine if I could...  \n",
              "2  When the polio vaccine dropped in 1955 people ...  \n",
              "3  I asked my mom if she felt any side effects fr...  \n",
              "4  A 6-year old ballet student asked me today if ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49883b0a-2d2b-437d-bc73-fff801873cde\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_url</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>COVID-19</td>\n",
              "      <td>1425267281202909184</td>\n",
              "      <td>http://twitter.com/user/status/142526728120290...</td>\n",
              "      <td>i was a vaccine checker tonight at my venue an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>COVID-19</td>\n",
              "      <td>1387113304959504384</td>\n",
              "      <td>http://twitter.com/user/status/138711330495950...</td>\n",
              "      <td>I asked the nurse giving my vaccine if I could...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>COVID-19</td>\n",
              "      <td>1379498353294069760</td>\n",
              "      <td>http://twitter.com/user/status/137949835329406...</td>\n",
              "      <td>When the polio vaccine dropped in 1955 people ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>COVID-19</td>\n",
              "      <td>1369843850223759362</td>\n",
              "      <td>http://twitter.com/user/status/136984385022375...</td>\n",
              "      <td>I asked my mom if she felt any side effects fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>COVID-19</td>\n",
              "      <td>1352425395375759363</td>\n",
              "      <td>http://twitter.com/user/status/135242539537575...</td>\n",
              "      <td>A 6-year old ballet student asked me today if ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49883b0a-2d2b-437d-bc73-fff801873cde')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49883b0a-2d2b-437d-bc73-fff801873cde button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49883b0a-2d2b-437d-bc73-fff801873cde');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ],
      "source": [
        "df_test.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqHCbjmpl8kT"
      },
      "source": [
        "# Predicting\n",
        "Go through the test set one by one and predict the values. Write to an output file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "dLI8lAglmUh6"
      },
      "outputs": [],
      "source": [
        "def predict(model, test_data, mapping=lambda x: x):\n",
        "\n",
        "    test_data['test_input'] = [tokenizer(text, padding='max_length', max_length=512, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in test_data['tweet_text']]\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        with open(results_fpath, \"w\") as results_file:\n",
        "          results_file.write(\"topic\\ttweet_id\\tclass_label\\trun_id\\n\") \n",
        "          for topic, tweet_id, _, _, test_input in test_data.values:\n",
        "\n",
        "                mask = test_input['attention_mask'].to(device)\n",
        "                input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask).argmax(dim=1)[0].item()\n",
        "                results_file.write(f'{topic}\\t{tweet_id}\\t{mapping(output)}\\t{run_id}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "LoqmQXSdKeO9"
      },
      "outputs": [],
      "source": [
        "# predict(model_1A, df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn2Xi8VwkENr"
      },
      "source": [
        "# Evaluation\n",
        "All of the code below is provided by the creators of CLEF for scoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "hOocXBNNh_EF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "import re\n",
        "_LINE_PATTERN_A = re.compile('^[1-9][0-9]{16,22}\\t([-+]?\\d*\\.\\d+|\\d+)$')\n",
        "\n",
        "def check_format(file_path):\n",
        "    with open(file_path, encoding='UTF-8') as out:\n",
        "        next(out)\n",
        "        file_content = out.read().strip()\n",
        "        for i, line in enumerate(file_content.split('\\n')):\n",
        "            topic_id, tweet_id, score, run_id = line.strip().split('\\t')\n",
        "\n",
        "            if not _LINE_PATTERN_A.match(\"%s\\t%s\"%(tweet_id, score)):\n",
        "                # 1. Check line format.\n",
        "                logging.error(f\"Wrong line format: {line}\")\n",
        "                return False\n",
        "            tweet_id = int(tweet_id)\n",
        "            score = float(score.strip())\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "import logging\n",
        "\n",
        "def _read_gold_and_pred(gold_fpath, pred_fpath):\n",
        "    \"\"\"\n",
        "    Read gold and predicted data.\n",
        "    :param gold_fpath: the original annotated gold file, where the last 4th column contains the labels.\n",
        "    :param pred_fpath: a file with line_number and score at each line.\n",
        "    :return: {line_number:label} dict; list with (line_number, score) tuples.\n",
        "    \"\"\"\n",
        "\n",
        "    logging.info(\"Reading gold labels from file {}\".format(gold_fpath))\n",
        "\n",
        "    gold_labels = {}\n",
        "    with open(gold_fpath, encoding='utf-8') as gold_f:\n",
        "        next(gold_f)\n",
        "        for line_res in gold_f:\n",
        "            (topic_id, tweet_id, tweet_url, tweet_text, check_worthiness) = line_res.strip().split('\\t')  # process the line from the res file\n",
        "            if topic_id == 'topic':\n",
        "                continue\n",
        "            label = check_worthiness\n",
        "            gold_labels[str(tweet_id)] = label\n",
        "\n",
        "    logging.info('Reading predicted labels from file {}'.format(pred_fpath))\n",
        "\n",
        "    line_score = []\n",
        "    # labels=[]\n",
        "    with open(pred_fpath) as pred_f:\n",
        "        next(pred_f)\n",
        "        for line in pred_f:\n",
        "            topic_id, tweet_id, score, run_id  = line.split('\\t')\n",
        "            tweet_id = str(tweet_id.strip())\n",
        "            # score = float(score.strip())\n",
        "            score = score.strip()\n",
        "\n",
        "            if tweet_id not in gold_labels:\n",
        "                logging.error('No such tweet_id: {} in gold file!'.format(tweet_id))\n",
        "                quit()\n",
        "            line_score.append((tweet_id, score))\n",
        "            # labels.append(score)\n",
        "\n",
        "\n",
        "    if len(set(gold_labels).difference([tup[0] for tup in line_score])) != 0:\n",
        "        logging.error('The predictions do not match the lines from the gold file - missing or extra line_no')\n",
        "        raise ValueError('The predictions do not match the lines from the gold file - missing or extra line_no')\n",
        "\n",
        "    return gold_labels, line_score\n",
        "\n",
        "def evaluate(gold_fpath, pred_fpath, subtask=\"checkworthy\"):\n",
        "    \"\"\"\n",
        "    Evaluates the predicted line rankings w.r.t. a gold file.\n",
        "    Metrics are: Average Precision, R-Pr, Reciprocal Rank, Precision@N\n",
        "    :param gold_fpath: the original annotated gold file, where the last 4th column contains the labels.\n",
        "    :param pred_fpath: a file with line_number at each line, where the list is ordered by check-worthiness.\n",
        "    :param thresholds: thresholds used for Reciprocal Rank@N and Precision@N.\n",
        "    If not specified - 1, 3, 5, 10, 20, 50, len(ranked_lines).\n",
        "    \"\"\"\n",
        "    gold_labels_dict, pred_labels_dict = _read_gold_and_pred(gold_fpath, pred_fpath)\n",
        "    gold_labels=[]\n",
        "    pred_labels=[]\n",
        "    for t_id, label in gold_labels_dict.items():\n",
        "        gold_labels.append(label)\n",
        "    for t_id, label in pred_labels_dict:\n",
        "        pred_labels.append(label)\n",
        "    # ranked_lines = [t[0] for t in sorted(line_score, key=lambda x: x[1], reverse=True)]\n",
        "    # if thresholds is None or len(thresholds) == 0:\n",
        "    #     thresholds = MAIN_THRESHOLDS + [len(ranked_lines)]\n",
        "\n",
        "    # Calculate Metrics\n",
        "    # precisions = _compute_precisions(gold_labels, ranked_lines, len(ranked_lines))\n",
        "    # precision = _compute_average_precision(gold_labels, pred_labels)\n",
        "    # reciprocal_rank = _compute_reciprocal_rank(gold_labels, ranked_lines)\n",
        "    # num_relevant = len({k for k, v in gold_labels.items() if v == 1})\n",
        "    if(subtask == \"checkworthy\" or subtask == \"harmful\"):\n",
        "        acc = accuracy_score(gold_labels, pred_labels)\n",
        "        precision = precision_score(gold_labels, pred_labels, pos_label='1',average='binary')\n",
        "        recall = recall_score(gold_labels, pred_labels, pos_label='1',average='binary')\n",
        "        f1=f1_score(gold_labels, pred_labels, pos_label='1',average='binary')\n",
        "    elif(subtask == \"attentionworthy\"):\n",
        "        acc = accuracy_score(gold_labels, pred_labels)\n",
        "        precision = precision_score(gold_labels, pred_labels, average = 'weighted')\n",
        "        recall = recall_score(gold_labels, pred_labels, average = 'weighted')\n",
        "        f1 = f1_score(gold_labels, pred_labels, average = 'weighted')\n",
        "    elif (subtask == \"claim\"):\n",
        "        acc=accuracy_score(gold_labels, pred_labels)\n",
        "        precision = precision_score(gold_labels, pred_labels, average = 'weighted')\n",
        "        recall = recall_score(gold_labels, pred_labels, average = 'weighted')\n",
        "        f1 = f1_score(gold_labels, pred_labels, average = 'weighted')\n",
        "\n",
        "    return acc, precision, recall, f1\n",
        "\n",
        "\n",
        "def validate_files(pred_file, subtask):\n",
        "    if not check_format(pred_file):\n",
        "        logging.error('Bad format for pred file {}. Cannot score.'.format(pred_file))\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "line_separator = '=' * 120\n",
        "\n",
        "MAIN_THRESHOLDS = [1, 3, 5, 10, 20, 50]\n",
        "\n",
        "def score(pred_file, gold_file, subtask):\n",
        "  if validate_files(pred_file, subtask):\n",
        "    acc, precision, recall, f1 = evaluate(gold_file, pred_file, subtask=subtask)\n",
        "    print(\"acc: {}, P:{}, R:{}, F1:{}\".format(acc, precision, recall, f1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gold_file = f'/content/data/CT22_{lang}_{subtask_id}_{subtask}_test_gold.tsv'\n",
        "\n",
        "# score(results_fpath, gold_file, subtask)"
      ],
      "metadata": {
        "id": "1WcLtcOsAgQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang='bulgarian'\n",
        "subtask='checkworthy'\n",
        "subtask_id='1A'\n",
        "results_fpath=f'/content/data/subtask{subtask_id}_{subtask}_{lang}.tsv'\n",
        "\n",
        "df_train, df_valid, df_test = prepare_data(lang, subtask, subtask_id)\n",
        "\n",
        "transformer=get_transformer(model_name)\n",
        "model_1A_bulgarian = BertClassifier(transformer)\n",
        "              \n",
        "train(model_1A_bulgarian, df_train, df_valid, LR, EPOCHS)\n",
        "\n",
        "torch.save(model_1A_bulgarian.state_dict(), f\"model_{lang}_{subtask}_{subtask_id}_{EPOCHS}_epochs.bin\")\n",
        "\n",
        "predict(model_1A_bulgarian, df_test)\n",
        "\n",
        "gold_file = f'/content/data/CT22_{lang}_{subtask_id}_{subtask}_test_gold.tsv'\n",
        "\n",
        "score(results_fpath, gold_file, subtask)"
      ],
      "metadata": {
        "id": "vBruPO2aLkP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang='english'\n",
        "subtask='checkworthy'\n",
        "subtask_id='1A'\n",
        "results_fpath=f'/content/data/subtask{subtask_id}_{subtask}_{lang}.tsv'\n",
        "\n",
        "df_train, df_valid, df_test = prepare_data(lang, subtask, subtask_id)\n",
        "\n",
        "transformer=get_transformer(model_name)\n",
        "model_1A = BertClassifier(transformer)\n",
        "              \n",
        "train(model_1A, df_train, df_valid, LR, EPOCHS)\n",
        "\n",
        "torch.save(model_1A.state_dict(), f\"model_{lang}_{subtask}_{subtask_id}_{EPOCHS}_epochs.bin\")\n",
        "\n",
        "predict(model_1A, df_test)\n",
        "\n",
        "gold_file = f'/content/data/CT22_{lang}_{subtask_id}_{subtask}_test_gold.tsv'\n",
        "\n",
        "score(results_fpath, gold_file, subtask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0olg7lvBb5RB",
        "outputId": "e3166014-8e91-427a-b3e6-f9eda2a7b19f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 1061/1061 [03:49<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.275 | Train Accuracy:  0.758 | Val Loss:  0.277 | Val Accuracy:  0.774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1061/1061 [03:49<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.251 | Train Accuracy:  0.789 | Val Loss:  0.267 | Val Accuracy:  0.774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1061/1061 [03:49<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.221 | Train Accuracy:  0.787 | Val Loss:  0.233 | Val Accuracy:  0.779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 753/1061 [02:42<01:06,  4.60it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tOFFqtqZtHB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPB693YaZtRa"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6Bqn_9kZtUO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9947OJVZtWT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNVCKBU4ZtYf"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIg6FOJXZtbW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9v5anLAZtkK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX06ovHiZtmc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FN6lY9UZtpC"
      },
      "source": [
        "**Subtask 1B:** Verifiable factual claims detection: Given a tweet, predict whether it contains a verifiable factual claim. This is a binary task with two labels: Yes and No. This is a classification task. This subtasks runs in 5 languages:\n",
        "\n",
        "- Arabic\n",
        "- Bulgarian\n",
        "- Dutch\n",
        "- English\n",
        "- Turkish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "tjKzHIvqJWQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f4ccaaa-6777-4fd1-e193-3c9bc43b3737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 1662/1662 [06:09<00:00,  4.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.328 | Train Accuracy:  0.640 | Val Loss:  0.329 | Val Accuracy:  0.635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1662/1662 [06:09<00:00,  4.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.319 | Train Accuracy:  0.638 | Val Loss:  0.315 | Val Accuracy:  0.638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1662/1662 [06:08<00:00,  4.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.293 | Train Accuracy:  0.660 | Val Loss:  0.327 | Val Accuracy:  0.645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1662/1662 [06:08<00:00,  4.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  0.251 | Train Accuracy:  0.749 | Val Loss:  0.325 | Val Accuracy:  0.629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1662/1662 [06:08<00:00,  4.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  0.198 | Train Accuracy:  0.822 | Val Loss:  0.369 | Val Accuracy:  0.622\n",
            "acc: 0.3784860557768924, P:0.40506103440120794, R:0.3784860557768924, F1:0.37978844085178215\n"
          ]
        }
      ],
      "source": [
        "lang='english'\n",
        "subtask='claim'\n",
        "subtask_id='1B'\n",
        "results_fpath=f'/content/data/subtask{subtask_id}_{subtask}_{lang}.tsv'\n",
        "\n",
        "df_train, df_valid, df_test = prepare_data(lang, subtask, subtask_id)\n",
        "\n",
        "transformer=get_transformer(model_name)\n",
        "model_1B = BertClassifier(transformer)\n",
        "              \n",
        "train(model_1B, df_train, df_valid, LR, EPOCHS)\n",
        "\n",
        "torch.save(model_1B.state_dict(), f\"model_{lang}_{subtask}_{subtask_id}_{EPOCHS}_epochs.bin\")\n",
        "\n",
        "predict(model_1B, df_test)\n",
        "\n",
        "gold_file = f'/content/data/CT22_{lang}_{subtask_id}_{subtask}_test_gold.tsv'\n",
        "\n",
        "score(results_fpath, gold_file, subtask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlnNtT3gLSxd"
      },
      "source": [
        "**Subtask 1C:** Harmful tweet detection : Given a tweet, predict whether it is harmful to the society and why. This task is defined with binary labels: Yes and No. This is a classification task. This subtasks runs in 5 languages:\n",
        "\n",
        "- Arabic\n",
        "- Bulgarian\n",
        "- Dutch\n",
        "- English\n",
        "- Turkish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "37QQqnhLLgjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b506f50-1346-48a8-f6c8-d339f43773d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 1662/1662 [05:49<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.177 | Train Accuracy:  0.896 | Val Loss:  0.159 | Val Accuracy:  0.899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1662/1662 [05:58<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.139 | Train Accuracy:  0.912 | Val Loss:  0.139 | Val Accuracy:  0.899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1662/1662 [05:58<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.115 | Train Accuracy:  0.912 | Val Loss:  0.144 | Val Accuracy:  0.899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1662/1662 [05:57<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  0.093 | Train Accuracy:  0.914 | Val Loss:  0.135 | Val Accuracy:  0.899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1662/1662 [05:56<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  0.073 | Train Accuracy:  0.914 | Val Loss:  0.136 | Val Accuracy:  0.899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1662/1662 [05:58<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 6 | Train Loss:  0.058 | Train Accuracy:  0.915 | Val Loss:  0.140 | Val Accuracy:  0.899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1662/1662 [05:58<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 7 | Train Loss:  0.048 | Train Accuracy:  0.919 | Val Loss:  0.198 | Val Accuracy:  0.899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1662/1662 [05:57<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 8 | Train Loss:  0.043 | Train Accuracy:  0.924 | Val Loss:  0.139 | Val Accuracy:  0.912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1662/1662 [05:57<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 9 | Train Loss:  0.039 | Train Accuracy:  0.925 | Val Loss:  0.146 | Val Accuracy:  0.902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1662/1662 [05:59<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 10 | Train Loss:  0.035 | Train Accuracy:  0.933 | Val Loss:  0.173 | Val Accuracy:  0.909\n",
            "acc: 0.8286852589641435, P:0.4, R:0.15, F1:0.21818181818181814\n"
          ]
        }
      ],
      "source": [
        "lang='english'\n",
        "subtask='harmful'\n",
        "subtask_id='1C'\n",
        "results_fpath=f'/content/data/subtask{subtask_id}_{subtask}_{lang}.tsv'\n",
        "\n",
        "df_train, df_valid, df_test = prepare_data(lang, subtask, subtask_id)\n",
        "\n",
        "transformer = get_transformer(model_name)\n",
        "model_1C = BertClassifier(transformer)\n",
        "              \n",
        "train(model_1C, df_train, df_valid, LR, EPOCHS)\n",
        "\n",
        "torch.save(model_1C.state_dict(), f\"model_{lang}_{subtask}_{subtask_id}_{EPOCHS}_epochs.bin\")\n",
        "\n",
        "predict(model_1C, df_test)\n",
        "\n",
        "gold_file = f'/content/data/CT22_{lang}_{subtask_id}_{subtask}_test_gold.tsv'\n",
        "\n",
        "score(results_fpath, gold_file, subtask)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Subtask 1D:** Attention-worthy tweet detection: Given a tweet, predict whether it should get the attention of policy makers and why. This task is defined with nine class labels: (i) No, not interesting, (ii) Yes, asks question, (iii) Yes, blame authorities, (iv) Yes, calls for action, (v) Yes, classified as in harmful task, (vi) Yes, contains advice, (vii) Yes, discusses action taken, (viii) Yes, discusses cure, and (ix) Yes, other. This is a classification task. This subtasks runs in 5 languages:\n",
        "\n",
        "- Arabic\n",
        "- Bulgarian\n",
        "- Dutch\n",
        "- English\n",
        "- Turkish"
      ],
      "metadata": {
        "id": "B7_1aRoBOC9d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "jmSXcwwY__oL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bbf4a03-da8b-40b7-c077-299d336f01e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 1661/1661 [05:53<00:00,  4.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.442 | Train Accuracy:  0.806 | Val Loss:  0.294 | Val Accuracy:  0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1661/1661 [05:58<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.328 | Train Accuracy:  0.859 | Val Loss:  0.285 | Val Accuracy:  0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1661/1661 [05:57<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.297 | Train Accuracy:  0.859 | Val Loss:  0.297 | Val Accuracy:  0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1661/1661 [05:57<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  0.264 | Train Accuracy:  0.859 | Val Loss:  0.256 | Val Accuracy:  0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1661/1661 [05:58<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  0.235 | Train Accuracy:  0.865 | Val Loss:  0.262 | Val Accuracy:  0.853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Wrong line format: COVID-19\t1333505660407963648\tno_not_interesting\tizarabadzh\n",
            "ERROR:root:Bad format for pred file /content/data/subtask1D_attentionworthy_english.tsv. Cannot score.\n"
          ]
        }
      ],
      "source": [
        "lang='english'\n",
        "subtask='attentionworthy'\n",
        "subtask_id='1D'\n",
        "results_fpath=f'/content/data/subtask{subtask_id}_{subtask}_{lang}.tsv'\n",
        "\n",
        "df_train, df_valid, df_test = prepare_data(lang, subtask, subtask_id)\n",
        "\n",
        "labels=encode_labels(df_train['label'])\n",
        "output_to_label=inverse_dict(labels)\n",
        "\n",
        "transformer = get_transformer(model_name)\n",
        "model_1D = BertClassifier(transformer, target=len(labels))\n",
        "              \n",
        "train(model_1D, df_train, df_valid, LR, EPOCHS)\n",
        "\n",
        "torch.save(model_1D.state_dict(), f\"model_{lang}_{subtask}_{subtask_id}_{EPOCHS}_epochs.bin\")\n",
        "\n",
        "predict(model_1D, df_test, lambda x: output_to_label[x])\n",
        "\n",
        "gold_file = f'/content/data/CT22_{lang}_{subtask_id}_{subtask}_test_gold.tsv'\n",
        "\n",
        "score(results_fpath, gold_file, subtask)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirement.txt"
      ],
      "metadata": {
        "id": "2KuCOoRYFB6S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CLEF2022Task1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMof0NWbCWxraBbW+AnvPK7",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}